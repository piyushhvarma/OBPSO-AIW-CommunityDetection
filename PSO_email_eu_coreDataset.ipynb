{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRxkeWnfENy5",
        "outputId": "4863731b-a31a-4758-c3f2-7c7ff7b2dd4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting email-eu-core.txt from email-Eu-core.txt.gz...\n",
            "Extraction successful.\n",
            "Loading graph from local file (email-eu-core.txt)...\n",
            "Data Loaded Successfully: Email-Eu-core LCC has 986 users and 16687 edges.\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "import random\n",
        "import math\n",
        "import gzip # Import for GZIP file handling\n",
        "import io\n",
        "\n",
        "# --- CONFIGURATION: ASSUMED LOCAL DATASET FILE ---\n",
        "FILENAME_ARCHIVE = \"email-Eu-core.txt.gz\"\n",
        "FILENAME_EDGE_LIST = \"email-eu-core.txt\" # The name of the file after extraction\n",
        "\n",
        "# Define a list of expected header/comment characters to skip\n",
        "SKIP_CHARS = ('%', '#', '*')\n",
        "\n",
        "# --- 1. EXTRACT DATA FROM ARCHIVE (GZIP) ---\n",
        "print(f\"Extracting {FILENAME_EDGE_LIST} from {FILENAME_ARCHIVE}...\")\n",
        "if not os.path.exists(FILENAME_ARCHIVE):\n",
        "    raise FileNotFoundError(f\"Error: The archive file '{FILENAME_ARCHIVE}' was not found. Please check the filename and path.\")\n",
        "\n",
        "if not os.path.exists(FILENAME_EDGE_LIST):\n",
        "    try:\n",
        "        # Use gzip to open the compressed file and write to the uncompressed file\n",
        "        with gzip.open(FILENAME_ARCHIVE, 'rb') as f_in:\n",
        "            with open(FILENAME_EDGE_LIST, 'wb') as f_out:\n",
        "                f_out.write(f_in.read())\n",
        "        print(\"Extraction successful.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during GZIP extraction: {e}\")\n",
        "        exit()\n",
        "else:\n",
        "    print(\"Edge list file already extracted.\")\n",
        "\n",
        "# --- 2. LOAD NETWORKX GRAPH (ROBUST EDGE LIST READING) ---\n",
        "print(f\"Loading graph from local file ({FILENAME_EDGE_LIST})...\")\n",
        "\n",
        "try:\n",
        "    # Filter file content to skip header/comment lines before loading\n",
        "    with open(FILENAME_EDGE_LIST, 'r') as f:\n",
        "        # Filter out lines starting with comment characters AND ensure lines are not empty\n",
        "        edge_lines = [line for line in f if not line.strip().startswith(SKIP_CHARS) and line.strip()]\n",
        "\n",
        "    # Write the clean edge data to an in-memory file for NetworkX to read\n",
        "    clean_data = \"\\n\".join(edge_lines)\n",
        "\n",
        "    G_full = nx.read_edgelist(\n",
        "        io.StringIO(clean_data), # Use the in-memory string as a file\n",
        "        create_using=nx.Graph(),\n",
        "        nodetype=int,\n",
        "        data=False,\n",
        "        encoding='utf-8'\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    G_full = nx.Graph()\n",
        "    print(f\"FATAL ERROR: Failed to read file as an edge list. Details: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. FILTER TO LARGEST CONNECTED COMPONENT (LCC) ---\n",
        "if G_full.number_of_nodes() == 0:\n",
        "    raise ValueError(\"The graph loaded zero nodes. Check the file content.\")\n",
        "\n",
        "largest_cc = max(nx.connected_components(G_full), key=len)\n",
        "G = G_full.subgraph(largest_cc).copy()\n",
        "\n",
        "# --- 4. CREATE INDEX MAPPING ---\n",
        "node_list = sorted(G.nodes())\n",
        "node_to_index = {node: i for i, node in enumerate(node_list)}\n",
        "index_to_node = {i: node for node, i in node_to_index.items()}\n",
        "NUM_USERS = G.number_of_nodes()\n",
        "DIMENSION = NUM_USERS # Define DIMENSION for subsequent PSO blocks\n",
        "\n",
        "print(f\"Data Loaded Successfully: Email-Eu-core LCC has {NUM_USERS} users and {G.number_of_edges()} edges.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_modularity(G, community_assignment_array):\n",
        "    \"\"\"\n",
        "    Calculates the Modularity (Q) of a community assignment for the Facebook graph.\n",
        "    \"\"\"\n",
        "    node_assignment = {index_to_node[i]: community_assignment_array[i]\n",
        "                       for i in range(NUM_USERS)}\n",
        "\n",
        "    communities = {}\n",
        "    for node, c_id in node_assignment.items():\n",
        "        if c_id not in communities:\n",
        "            communities[c_id] = set()\n",
        "        communities[c_id].add(node)\n",
        "\n",
        "    partition = list(communities.values())\n",
        "\n",
        "    try:\n",
        "        Q = nx.community.modularity(G, partition)\n",
        "    except ZeroDivisionError:\n",
        "        Q = 0.0\n",
        "\n",
        "    return Q"
      ],
      "metadata": {
        "id": "yv-jhd8OF32L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PSO HYPERPARAMETERS ---\n",
        "NUM_PARTICLES = 50\n",
        "MAX_ITERATIONS = 100\n",
        "NUM_CLUSTERS = 30       # Target number of communities (K)\n",
        "W_MAX = 0.9\n",
        "W_MIN = 0.4\n",
        "C1 = 2.0\n",
        "C2 = 2.0\n",
        "V_MAX = 6.0\n",
        "\n",
        "# --- PARTICLE CLASS ---\n",
        "class Particle:\n",
        "    def __init__(self, dimension, K):\n",
        "        self.dimension = dimension\n",
        "        self.K = K\n",
        "        self.position = np.random.randint(0, self.K, size=self.dimension)\n",
        "        self.velocity = np.zeros(self.dimension, dtype=float)\n",
        "        self.pbest_position = self.position.copy()\n",
        "        self.pbest_fitness = -1.0\n",
        "        self.current_fitness = -1.0\n",
        "\n",
        "# --- INITIALIZATION & MAIN DPSO LOOP ---\n",
        "print(f\"\\n--- Starting Discrete PSO for Facebook Community Detection (K={NUM_CLUSTERS}) ---\")\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "swarm = [Particle(DIMENSION, NUM_CLUSTERS) for _ in range(NUM_PARTICLES)]\n",
        "gbest_position = swarm[0].position.copy()\n",
        "gbest_fitness = -1.0\n",
        "\n",
        "for iter in range(MAX_ITERATIONS):\n",
        "    # Dynamic Inertia Weight\n",
        "    w = W_MAX - (W_MAX - W_MIN) * iter / MAX_ITERATIONS\n",
        "\n",
        "    for particle in swarm:\n",
        "        particle.current_fitness = calculate_modularity(G, particle.position)\n",
        "\n",
        "        if particle.current_fitness > particle.pbest_fitness:\n",
        "            particle.pbest_fitness = particle.current_fitness\n",
        "            particle.pbest_position = particle.position.copy()\n",
        "\n",
        "            if particle.pbest_fitness > gbest_fitness:\n",
        "                gbest_fitness = particle.pbest_fitness\n",
        "                gbest_position = particle.pbest_position.copy()\n",
        "\n",
        "    for particle in swarm:\n",
        "        r1 = np.random.rand(DIMENSION)\n",
        "        r2 = np.random.rand(DIMENSION)\n",
        "\n",
        "        cognitive_term = C1 * r1 * (particle.pbest_position - particle.position)\n",
        "        social_term = C2 * r2 * (gbest_position - particle.position)\n",
        "\n",
        "        new_velocity = w * particle.velocity + cognitive_term + social_term\n",
        "        new_velocity = np.clip(new_velocity, -V_MAX, V_MAX)\n",
        "        particle.velocity = new_velocity\n",
        "\n",
        "        for i in range(DIMENSION):\n",
        "            p_switch = 1.0 / (1.0 + math.exp(-particle.velocity[i]))\n",
        "\n",
        "            if random.random() < p_switch:\n",
        "                pbest_assignment = particle.pbest_position[i]\n",
        "                gbest_assignment = gbest_position[i]\n",
        "\n",
        "                if random.random() < 0.5:\n",
        "                    particle.position[i] = gbest_assignment\n",
        "                else:\n",
        "                    particle.position[i] = pbest_assignment\n",
        "\n",
        "            particle.position[i] = int(particle.position[i] % NUM_CLUSTERS)\n",
        "\n",
        "\n",
        "    print(f\"Iteration {iter+1}/{MAX_ITERATIONS}: Global Best Modularity = {gbest_fitness:.4f}\")\n",
        "\n",
        "# --- FINAL RESULT ---\n",
        "print(\"\\n--- OPTIMIZATION COMPLETE ---\")\n",
        "print(f\"Final Best Modularity Score: {gbest_fitness:.4f}\")\n",
        "\n",
        "final_assignments = {index_to_node[i]: gbest_position[i] for i in range(DIMENSION)}\n",
        "community_counts = Counter(final_assignments.values())\n",
        "print(f\"Number of distinct communities found: {len(community_counts)}\")\n",
        "print(\"Top 5 largest communities (size):\", community_counts.most_common(5))"
      ],
      "metadata": {
        "id": "oMAkV-kwF78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c65f5a5-c299-4374-8a91-eb4fb5765db8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Discrete PSO for Facebook Community Detection (K=30) ---\n",
            "Iteration 1/100: Global Best Modularity = 0.0364\n",
            "Iteration 2/100: Global Best Modularity = 0.0364\n",
            "Iteration 3/100: Global Best Modularity = 0.0366\n",
            "Iteration 4/100: Global Best Modularity = 0.0372\n",
            "Iteration 5/100: Global Best Modularity = 0.0379\n",
            "Iteration 6/100: Global Best Modularity = 0.0385\n",
            "Iteration 7/100: Global Best Modularity = 0.0386\n",
            "Iteration 8/100: Global Best Modularity = 0.0386\n",
            "Iteration 9/100: Global Best Modularity = 0.0386\n",
            "Iteration 10/100: Global Best Modularity = 0.0388\n",
            "Iteration 11/100: Global Best Modularity = 0.0388\n",
            "Iteration 12/100: Global Best Modularity = 0.0395\n",
            "Iteration 13/100: Global Best Modularity = 0.0395\n",
            "Iteration 14/100: Global Best Modularity = 0.0395\n",
            "Iteration 15/100: Global Best Modularity = 0.0395\n",
            "Iteration 16/100: Global Best Modularity = 0.0395\n",
            "Iteration 17/100: Global Best Modularity = 0.0395\n",
            "Iteration 18/100: Global Best Modularity = 0.0395\n",
            "Iteration 19/100: Global Best Modularity = 0.0395\n",
            "Iteration 20/100: Global Best Modularity = 0.0395\n",
            "Iteration 21/100: Global Best Modularity = 0.0395\n",
            "Iteration 22/100: Global Best Modularity = 0.0395\n",
            "Iteration 23/100: Global Best Modularity = 0.0395\n",
            "Iteration 24/100: Global Best Modularity = 0.0395\n",
            "Iteration 25/100: Global Best Modularity = 0.0395\n",
            "Iteration 26/100: Global Best Modularity = 0.0395\n",
            "Iteration 27/100: Global Best Modularity = 0.0395\n",
            "Iteration 28/100: Global Best Modularity = 0.0395\n",
            "Iteration 29/100: Global Best Modularity = 0.0395\n",
            "Iteration 30/100: Global Best Modularity = 0.0395\n",
            "Iteration 31/100: Global Best Modularity = 0.0395\n",
            "Iteration 32/100: Global Best Modularity = 0.0395\n",
            "Iteration 33/100: Global Best Modularity = 0.0395\n",
            "Iteration 34/100: Global Best Modularity = 0.0395\n",
            "Iteration 35/100: Global Best Modularity = 0.0395\n",
            "Iteration 36/100: Global Best Modularity = 0.0395\n",
            "Iteration 37/100: Global Best Modularity = 0.0395\n",
            "Iteration 38/100: Global Best Modularity = 0.0395\n",
            "Iteration 39/100: Global Best Modularity = 0.0395\n",
            "Iteration 40/100: Global Best Modularity = 0.0395\n",
            "Iteration 41/100: Global Best Modularity = 0.0395\n",
            "Iteration 42/100: Global Best Modularity = 0.0395\n",
            "Iteration 43/100: Global Best Modularity = 0.0395\n",
            "Iteration 44/100: Global Best Modularity = 0.0395\n",
            "Iteration 45/100: Global Best Modularity = 0.0395\n",
            "Iteration 46/100: Global Best Modularity = 0.0395\n",
            "Iteration 47/100: Global Best Modularity = 0.0395\n",
            "Iteration 48/100: Global Best Modularity = 0.0395\n",
            "Iteration 49/100: Global Best Modularity = 0.0395\n",
            "Iteration 50/100: Global Best Modularity = 0.0395\n",
            "Iteration 51/100: Global Best Modularity = 0.0395\n",
            "Iteration 52/100: Global Best Modularity = 0.0395\n",
            "Iteration 53/100: Global Best Modularity = 0.0395\n",
            "Iteration 54/100: Global Best Modularity = 0.0395\n",
            "Iteration 55/100: Global Best Modularity = 0.0395\n",
            "Iteration 56/100: Global Best Modularity = 0.0395\n",
            "Iteration 57/100: Global Best Modularity = 0.0395\n",
            "Iteration 58/100: Global Best Modularity = 0.0395\n",
            "Iteration 59/100: Global Best Modularity = 0.0395\n",
            "Iteration 60/100: Global Best Modularity = 0.0395\n",
            "Iteration 61/100: Global Best Modularity = 0.0395\n",
            "Iteration 62/100: Global Best Modularity = 0.0395\n",
            "Iteration 63/100: Global Best Modularity = 0.0395\n",
            "Iteration 64/100: Global Best Modularity = 0.0395\n",
            "Iteration 65/100: Global Best Modularity = 0.0395\n",
            "Iteration 66/100: Global Best Modularity = 0.0395\n",
            "Iteration 67/100: Global Best Modularity = 0.0395\n",
            "Iteration 68/100: Global Best Modularity = 0.0395\n",
            "Iteration 69/100: Global Best Modularity = 0.0395\n",
            "Iteration 70/100: Global Best Modularity = 0.0395\n",
            "Iteration 71/100: Global Best Modularity = 0.0396\n",
            "Iteration 72/100: Global Best Modularity = 0.0396\n",
            "Iteration 73/100: Global Best Modularity = 0.0396\n",
            "Iteration 74/100: Global Best Modularity = 0.0396\n",
            "Iteration 75/100: Global Best Modularity = 0.0396\n",
            "Iteration 76/100: Global Best Modularity = 0.0396\n",
            "Iteration 77/100: Global Best Modularity = 0.0396\n",
            "Iteration 78/100: Global Best Modularity = 0.0396\n",
            "Iteration 79/100: Global Best Modularity = 0.0396\n",
            "Iteration 80/100: Global Best Modularity = 0.0396\n",
            "Iteration 81/100: Global Best Modularity = 0.0396\n",
            "Iteration 82/100: Global Best Modularity = 0.0396\n",
            "Iteration 83/100: Global Best Modularity = 0.0396\n",
            "Iteration 84/100: Global Best Modularity = 0.0396\n",
            "Iteration 85/100: Global Best Modularity = 0.0396\n",
            "Iteration 86/100: Global Best Modularity = 0.0396\n",
            "Iteration 87/100: Global Best Modularity = 0.0396\n",
            "Iteration 88/100: Global Best Modularity = 0.0396\n",
            "Iteration 89/100: Global Best Modularity = 0.0396\n",
            "Iteration 90/100: Global Best Modularity = 0.0396\n",
            "Iteration 91/100: Global Best Modularity = 0.0396\n",
            "Iteration 92/100: Global Best Modularity = 0.0396\n",
            "Iteration 93/100: Global Best Modularity = 0.0396\n",
            "Iteration 94/100: Global Best Modularity = 0.0396\n",
            "Iteration 95/100: Global Best Modularity = 0.0400\n",
            "Iteration 96/100: Global Best Modularity = 0.0400\n",
            "Iteration 97/100: Global Best Modularity = 0.0400\n",
            "Iteration 98/100: Global Best Modularity = 0.0400\n",
            "Iteration 99/100: Global Best Modularity = 0.0400\n",
            "Iteration 100/100: Global Best Modularity = 0.0400\n",
            "\n",
            "--- OPTIMIZATION COMPLETE ---\n",
            "Final Best Modularity Score: 0.0400\n",
            "Number of distinct communities found: 17\n",
            "Top 5 largest communities (size): [(np.int64(29), 214), (np.int64(28), 187), (np.int64(27), 153), (np.int64(26), 114), (np.int64(25), 87)]\n"
          ]
        }
      ]
    }
  ]
}