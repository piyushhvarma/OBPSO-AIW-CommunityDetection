{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRxkeWnfENy5",
        "outputId": "467a3a4d-c018-45f9-b208-38cc3113f717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading graph from local file (soc-dolphins.mtx - Matrix Market format)...\n",
            "Graph Loaded: Dolphin Network has 62 nodes.\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from collections import Counter\n",
        "import io\n",
        "import scipy.io # <-- Import SciPy for Matrix Market format\n",
        "\n",
        "# --- CONFIGURATION: ASSUMED LOCAL DATASET FILE (MTX) ---\n",
        "FILENAME_MTX = \"soc-dolphins.mtx\"\n",
        "\n",
        "# --- 1. LOAD GRAPH FROM MTX ---\n",
        "print(f\"Loading graph from local file ({FILENAME_MTX} - Matrix Market format)...\")\n",
        "if not os.path.exists(FILENAME_MTX):\n",
        "    # Fallback suggestion if the .mtx file is missing\n",
        "    print(\"NOTE: Trying to load directly from NetworkX as a fallback since .mtx file is missing.\")\n",
        "    G = nx.read_gml(\"dolphins.gml\")\n",
        "    print(\"Loaded via GML fallback.\")\n",
        "\n",
        "else:\n",
        "    try:\n",
        "        # Read the sparse matrix from the .mtx file\n",
        "        adj_matrix_sparse = scipy.io.mmread(FILENAME_MTX)\n",
        "\n",
        "        # Convert the sparse matrix to a NetworkX graph\n",
        "        G_full = nx.from_scipy_sparse_array(adj_matrix_sparse)\n",
        "\n",
        "        # Ensure it is treated as an undirected graph\n",
        "        G = nx.Graph(G_full)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"FATAL ERROR: Could not read {FILENAME_MTX} or convert to graph. Details: {e}\")\n",
        "        exit()\n",
        "\n",
        "# --- 2. CREATE INDEX MAPPING ---\n",
        "# Ensure the node IDs are sequential from 0 to N-1 for array processing\n",
        "node_list = sorted(G.nodes())\n",
        "node_to_index = {node: i for i, node in enumerate(node_list)}\n",
        "index_to_node = {i: node for node, i in node_to_index.items()}\n",
        "NUM_NODES = G.number_of_nodes()\n",
        "DIMENSION = NUM_NODES\n",
        "\n",
        "# --- 3. HYPERPARAMETERS (Adjusted for a small graph) ---\n",
        "NUM_PARTICLES = 50     # P_n: Total population size\n",
        "MAX_ITERATIONS = 50    # N_max: Maximum iterations\n",
        "W_MAX = 0.9\n",
        "W_MIN = 0.5\n",
        "C1 = 1.3\n",
        "C2 = 1.5\n",
        "V_MAX = 6.0\n",
        "A_i = 0                # Lower bound for cluster IDs\n",
        "B_i = NUM_NODES - 1    # Upper bound for cluster IDs\n",
        "NUM_CLUSTERS = 5       # Target number of communities (K)\n",
        "P_c = 0.2              # Ratio of crossover (20% of population)\n",
        "\n",
        "print(f\"Graph Loaded: Dolphin Network has {NUM_NODES} nodes.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_modularity(G, community_assignment_array):\n",
        "    \"\"\"Calculates the Modularity (Q) of a community assignment.\"\"\"\n",
        "\n",
        "    node_assignment = {}\n",
        "    for i in range(DIMENSION):\n",
        "        node_id = index_to_node[i]\n",
        "        community_id = community_assignment_array[i]\n",
        "        node_assignment[node_id] = community_id\n",
        "\n",
        "    communities = {}\n",
        "    for node, c_id in node_assignment.items():\n",
        "        if c_id not in communities:\n",
        "            communities[c_id] = set()\n",
        "        communities[c_id].add(node)\n",
        "\n",
        "    partition = list(communities.values())\n",
        "\n",
        "    if not partition or all(not c for c in partition):\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        Q = nx.community.modularity(G, partition)\n",
        "    except nx.exception.NotAPartition:\n",
        "        return -1.0\n",
        "    except ZeroDivisionError:\n",
        "        return 0.0\n",
        "\n",
        "    return Q"
      ],
      "metadata": {
        "id": "yv-jhd8OF32L"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STARTING REFINEMENT (Louvain Local Search) ---\n",
        "import community.community_louvain as community_louvain\n",
        "\n",
        "# The best partition found by PSO (format: {node: community_id})\n",
        "pso_partition_dict = {index_to_node[i]: gbest_position[i] for i in range(DIMENSION)}\n",
        "\n",
        "print(\"\\n--- STARTING REFINEMENT (Louvain Local Search) ---\")\n",
        "\n",
        "# Run Louvain optimization starting from the PSO-found partition\n",
        "# The community_louvain library finds the partition that maximizes modularity.\n",
        "refined_partition_dict = community_louvain.best_partition(\n",
        "    G,\n",
        "    partition=pso_partition_dict,\n",
        "    resolution=1.0,\n",
        "    weight='weight'\n",
        ")\n",
        "\n",
        "# --- NEW: Convert the Refined Partition Dictionary to the List-of-Sets Format ---\n",
        "# The community_louvain output is a dictionary, but nx.modularity needs a list of sets.\n",
        "\n",
        "# 1. Group nodes by their community ID from the refinement result\n",
        "refined_communities_sets = {}\n",
        "for node, community_id in refined_partition_dict.items():\n",
        "    if community_id not in refined_communities_sets:\n",
        "        refined_communities_sets[community_id] = set()\n",
        "    refined_communities_sets[community_id].add(node)\n",
        "\n",
        "# 2. Convert the dictionary values (the sets) into a list\n",
        "partition_for_modularity = list(refined_communities_sets.values())\n",
        "\n",
        "# --- ANALYZE REFINED RESULT ---\n",
        "\n",
        "# 1. Calculate the final, refined Modularity Score using the corrected format\n",
        "refined_modularity = nx.community.modularity(G, partition_for_modularity)\n",
        "\n",
        "# 2. Analyze results\n",
        "gbest_modularity = gbest_fitness # Renaming for clarity\n",
        "\n",
        "print(\"\\n--- FINAL OPTIMIZATION RESULTS ---\")\n",
        "print(f\"1. PSO Final Modularity: {gbest_modularity:.4f}\")\n",
        "print(f\"2. REFINED Final Modularity (Louvain Post-processing): {refined_modularity:.4f}\")\n",
        "\n",
        "if refined_modularity > gbest_modularity:\n",
        "    print(\"✨ Refinement IMPROVED the result!\")\n",
        "    final_modularity = refined_modularity\n",
        "    final_assignments = refined_partition_dict # Use the dictionary format for easy printing\n",
        "    final_community_counts = Counter(final_assignments.values())\n",
        "else:\n",
        "    print(\"⚠️ Refinement did NOT improve the result; using PSO's best.\")\n",
        "    final_modularity = gbest_modularity\n",
        "    final_assignments = pso_partition_dict\n",
        "    final_community_counts = Counter(final_assignments.values())\n",
        "\n",
        "# --- FINAL COMMUNITY MEMBERSHIP OUTPUT ---\n",
        "final_communities = {}\n",
        "for node, community_id in final_assignments.items():\n",
        "    if community_id not in final_communities:\n",
        "        final_communities[community_id] = []\n",
        "    final_communities[community_id].append(node)\n",
        "\n",
        "print(f\"\\nFinal Best Modularity Score: {final_modularity:.4f}\")\n",
        "print(f\"Total Communities: {len(final_communities)}\")\n",
        "print(\"Top 5 largest communities (size):\", final_community_counts.most_common(5))\n",
        "\n",
        "print(\"\\n--- COMMUNITY MEMBERSHIP EXAMPLES ---\")\n",
        "for cid, members in final_communities.items():\n",
        "    member_list = members[:10] + ['...'] if len(members) > 10 else members\n",
        "    print(f\"Community {cid} (Size: {len(members)}): {member_list}\")"
      ],
      "metadata": {
        "id": "oMAkV-kwF78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2302b346-39ea-4884-a61a-f61201020646"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STARTING REFINEMENT (Louvain Local Search) ---\n",
            "\n",
            "--- FINAL OPTIMIZATION RESULTS ---\n",
            "1. PSO Final Modularity: 0.0533\n",
            "2. REFINED Final Modularity (Louvain Post-processing): 0.3899\n",
            "✨ Refinement IMPROVED the result!\n",
            "\n",
            "Final Best Modularity Score: 0.3899\n",
            "Total Communities: 2\n",
            "Top 5 largest communities (size): [(np.int64(0), 39), (np.int64(1), 23)]\n",
            "\n",
            "--- COMMUNITY MEMBERSHIP EXAMPLES ---\n",
            "Community 0 (Size: 39): [0, 2, 3, 4, 8, 10, 11, 12, 14, 15, '...']\n",
            "Community 1 (Size: 23): [1, 5, 6, 7, 9, 13, 17, 19, 22, 25, '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ABz75rxBQ4QE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}